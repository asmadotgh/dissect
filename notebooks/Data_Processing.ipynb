{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "import argparse\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "sys.path.append(\"../\")\n",
    "from utils import *\n",
    "random_state = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose a dataset\n",
    "\n",
    "We currently have 2 options\n",
    "\n",
    "1. CelebA\n",
    "\n",
    "2. Standford Chest X-ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirpath = '../data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CelebA\n",
    "\n",
    "Code adopted from: https://github.com/taki0112/StarGAN-Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download CelebA dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_file_from_google_drive(id, destination):\n",
    "    URL = \"https://docs.google.com/uc?export=download\"\n",
    "    session = requests.Session()\n",
    "\n",
    "    response = session.get(URL, params={'id': id}, stream=True)\n",
    "    token = get_confirm_token(response)\n",
    "\n",
    "    if token:\n",
    "        params = {'id': id, 'confirm': token}\n",
    "        response = session.get(URL, params=params, stream=True)\n",
    "\n",
    "    save_response_content(response, destination)\n",
    "def get_confirm_token(response):\n",
    "    for key, value in response.cookies.items():\n",
    "        if key.startswith('download_warning'):\n",
    "            return value\n",
    "    return None\n",
    "def save_response_content(response, destination, chunk_size=32 * 1024):\n",
    "    total_size = int(response.headers.get('content-length', 0))\n",
    "    with open(destination, \"wb\") as f:\n",
    "        for chunk in tqdm(response.iter_content(chunk_size), total=total_size,\n",
    "                          unit='B', unit_scale=True, desc=destination):\n",
    "            if chunk:  # filter out keep-alive new chunks\n",
    "                f.write(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "celebA_dir = os.path.join(dirpath, 'CelebA')\n",
    "if not os.path.exists(celebA_dir):\n",
    "    os.makedirs(celebA_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/CelebA'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "celebA_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] ../data/CelebA/list_attr_celeba.txt already exists\n",
      "[*] ../data/img_align_celeba.zip already exists\n",
      "[*] already unzipped at ../data/CelebA/img_align_celeba.\n",
      "[*] ../data/CelebA/images already exists\n"
     ]
    }
   ],
   "source": [
    "file_name, drive_id = \"img_align_celeba.zip\", \"0B7EVK8r0v71pZjFTYXZWM3FlRnM\"\n",
    "txt_name, txt_drive_id = \"list_attr_celeba.txt\", \"0B7EVK8r0v71pblRyaVFSWGxPY0U\"\n",
    "\n",
    "save_path = os.path.join(dirpath, file_name)\n",
    "txt_save_path = os.path.join(celebA_dir, txt_name)\n",
    "\n",
    "if os.path.exists(txt_save_path):\n",
    "    print('[*] {} already exists'.format(txt_save_path))\n",
    "else:\n",
    "    download_file_from_google_drive(txt_drive_id, txt_save_path)\n",
    "\n",
    "if os.path.exists(save_path):\n",
    "    print('[*] {} already exists'.format(save_path))\n",
    "else:\n",
    "    download_file_from_google_drive(drive_id, save_path)\n",
    "\n",
    "unzipped = os.path.exists(os.path.join(celebA_dir, 'img_align_celeba'))\n",
    "if unzipped:\n",
    "    print ('[*] already unzipped at {}.'.format(os.path.join(celebA_dir, 'img_align_celeba')))\n",
    "else:\n",
    "    with zipfile.ZipFile(save_path) as zf:\n",
    "        zf.extractall(celebA_dir)\n",
    "# os.remove(save_path)\n",
    "my_images_dir = os.path.join(celebA_dir, 'images')\n",
    "if os.path.exists(my_images_dir):\n",
    "    print('[*] {} already exists'.format(my_images_dir))\n",
    "else:\n",
    "    os.rename(os.path.join(celebA_dir, 'img_align_celeba'), my_images_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "celebA_dir = os.path.join('../data', 'CelebA')\n",
    "image_dir = os.path.join(celebA_dir,'images')\n",
    "txt_dir = os.path.join(celebA_dir,'list_attr_celeba.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Dir:  ../data/CelebA/images\n",
      "Label File:  ../data/CelebA/list_attr_celeba.txt\n"
     ]
    }
   ],
   "source": [
    "print('Image Dir: ', image_dir)\n",
    "print('Label File: ',txt_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202599\n",
      "\n",
      "5_o_Clock_Shadow Arched_Eyebrows Attractive Bags_Under_Eyes Bald Bangs Big_Lips Big_Nose Black_Hair Blond_Hair Blurry Brown_Hair Bushy_Eyebrows Chubby Double_Chin Eyeglasses Goatee Gray_Hair Heavy_Makeup High_Cheekbones Male Mouth_Slightly_Open Mustache Narrow_Eyes No_Beard Oval_Face Pale_Skin Pointy_Nose Receding_Hairline Rosy_Cheeks Sideburns Smiling Straight_Hair Wavy_Hair Wearing_Earrings Wearing_Hat Wearing_Lipstick Wearing_Necklace Wearing_Necktie Young \n",
      "\n",
      "000001.jpg -1  1  1 -1 -1 -1 -1 -1 -1 -1 -1  1 -1 -1 -1 -1 -1 -1  1  1 -1  1 -1 -1  1 -1 -1  1 -1 -1 -1  1  1 -1  1 -1  1 -1 -1  1\n",
      "\n",
      "000002.jpg -1 -1 -1  1 -1 -1 -1  1 -1 -1 -1  1 -1 -1 -1 -1 -1 -1 -1  1 -1  1 -1 -1  1 -1 -1 -1 -1 -1 -1  1 -1 -1 -1 -1 -1 -1 -1  1\n",
      "\n",
      "000003.jpg -1 -1 -1 -1 -1 -1  1 -1 -1 -1  1 -1 -1 -1 -1 -1 -1 -1 -1 -1  1 -1 -1  1  1 -1 -1  1 -1 -1 -1 -1 -1  1 -1 -1 -1 -1 -1  1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read label file:\n",
    "fp = open(txt_dir, 'r')\n",
    "for i in range(5):\n",
    "    print(fp.readline())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divide dataset into train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(135741,) (66858,)\n"
     ]
    }
   ],
   "source": [
    "all_images = os.listdir(image_dir)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test = train_test_split(all_images, test_size=0.33, random_state=random_state)\n",
    "X_train = np.asarray(X_train)\n",
    "X_test = np.asarray(X_test)\n",
    "print(X_train.shape, X_test.shape)\n",
    "np.save(os.path.join(celebA_dir, 'train_ids.npy'), X_train)\n",
    "np.save(os.path.join(celebA_dir, 'test_ids.npy'), X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Label File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/CelebA/list_attr_celeba.txt'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['5_o_Clock_Shadow' 'Arched_Eyebrows' 'Attractive' 'Bags_Under_Eyes'\n",
      " 'Bald' 'Bangs' 'Big_Lips' 'Big_Nose' 'Black_Hair' 'Blond_Hair' 'Blurry'\n",
      " 'Brown_Hair' 'Bushy_Eyebrows' 'Chubby' 'Double_Chin' 'Eyeglasses'\n",
      " 'Goatee' 'Gray_Hair' 'Heavy_Makeup' 'High_Cheekbones' 'Male'\n",
      " 'Mouth_Slightly_Open' 'Mustache' 'Narrow_Eyes' 'No_Beard' 'Oval_Face'\n",
      " 'Pale_Skin' 'Pointy_Nose' 'Receding_Hairline' 'Rosy_Cheeks' 'Sideburns'\n",
      " 'Smiling' 'Straight_Hair' 'Wavy_Hair' 'Wearing_Earrings' 'Wearing_Hat'\n",
      " 'Wearing_Lipstick' 'Wearing_Necklace' 'Wearing_Necktie' 'Young']\n"
     ]
    }
   ],
   "source": [
    "categories, file_names_dict = read_data_file(txt_dir)\n",
    "categories = np.asarray(categories).ravel()\n",
    "print(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images:  202599\n",
      "Few image names:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['040892.jpg', '058624.jpg', '175595.jpg', '123543.jpg', '025808.jpg']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Number of images: \", len(file_names_dict.keys()))\n",
    "print(\"Few image names:\")\n",
    "list(file_names_dict.keys())[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "[-1. -1. -1.  1. -1. -1.  1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1.  1. -1. -1. -1.  1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1.  1.]\n"
     ]
    }
   ],
   "source": [
    "label = file_names_dict[list(file_names_dict.keys())[0]]\n",
    "print(type(label))\n",
    "label = np.asarray(label)\n",
    "print(label.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Binary-Classification Data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(202599, 41)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>Image_Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>000001.jpg</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>000001.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000002.jpg</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>000002.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0    1    2    3    4    5    6    7    8    9     ...       31  \\\n",
       "000001.jpg -1.0  1.0  1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0     ...      1.0   \n",
       "000002.jpg -1.0 -1.0 -1.0  1.0 -1.0 -1.0 -1.0  1.0 -1.0 -1.0     ...      1.0   \n",
       "\n",
       "             32   33   34   35   36   37   38   39  Image_Path  \n",
       "000001.jpg  1.0 -1.0  1.0 -1.0  1.0 -1.0 -1.0  1.0  000001.jpg  \n",
       "000002.jpg -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0  1.0  000002.jpg  \n",
       "\n",
       "[2 rows x 41 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the dictionary: attr_list to a dataframe\n",
    "df = pd.DataFrame(file_names_dict).T\n",
    "df['Image_Path'] = df.index\n",
    "print(df.shape)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_attribute_index(attribute):\n",
    "    # attribute: Target attribute for binary classification\n",
    "    index_main = []\n",
    "    for a in attribute:\n",
    "        print(a)\n",
    "        index = np.where(np.asarray(categories) == a)\n",
    "        index = index[0][0]\n",
    "        index_main.append(index)\n",
    "    print(index_main)\n",
    "    return index_main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write the label file for target attribute binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_attribute_label_file(attribute):\n",
    "    index_main = find_attribute_index(attribute)\n",
    "    #Train File\n",
    "    df_temp = df[['Image_Path']+ index_main]\n",
    "    file_name = ''.join(attribute)+'_binary_classification.txt'\n",
    "    df_temp.to_csv(os.path.join(celebA_dir, file_name ),sep = ' ', index = None, header = None)\n",
    "    print(df_temp.shape)\n",
    "    one_line = str(df_temp.shape[0]) + '\\n'\n",
    "    second_line = ''.join(attribute)+ \"\\n\"\n",
    "    with open(os.path.join(celebA_dir, file_name), 'r+') as fp:\n",
    "        lines = fp.readlines()     # lines is list of line, each element '...\\n'\n",
    "        lines.insert(0, one_line)  # you can use any index if you know the line index\n",
    "        lines.insert(1, second_line)\n",
    "        fp.seek(0)                 # file pointer locates at the beginning to write the whole file again\n",
    "        fp.writelines(lines) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smiling\n",
      "[31]\n",
      "(202599, 2)\n",
      "Young\n",
      "[39]\n",
      "(202599, 2)\n",
      "No_Beard\n",
      "[24]\n",
      "(202599, 2)\n",
      "Heavy_Makeup\n",
      "[18]\n",
      "(202599, 2)\n",
      "Black_Hair\n",
      "[8]\n",
      "(202599, 2)\n",
      "Bangs\n",
      "[5]\n",
      "(202599, 2)\n"
     ]
    }
   ],
   "source": [
    "attributes = [['Smiling'], ['Young'], ['No_Beard'], ['Heavy_Makeup'], ['Black_Hair'], ['Bangs']]\n",
    "for attribute in attributes:\n",
    "     write_attribute_label_file(attribute)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read saved files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Smiling']\n",
      "Number of images:  202599\n",
      "Few image names:\n",
      "<class 'list'>\n",
      "[-1.]\n",
      "['Young']\n",
      "Number of images:  202599\n",
      "Few image names:\n",
      "<class 'list'>\n",
      "[1.]\n",
      "['No_Beard']\n",
      "Number of images:  202599\n",
      "Few image names:\n",
      "<class 'list'>\n",
      "[1.]\n",
      "['Heavy_Makeup']\n",
      "Number of images:  202599\n",
      "Few image names:\n",
      "<class 'list'>\n",
      "[1.]\n",
      "['Black_Hair']\n",
      "Number of images:  202599\n",
      "Few image names:\n",
      "<class 'list'>\n",
      "[1.]\n",
      "['Bangs']\n",
      "Number of images:  202599\n",
      "Few image names:\n",
      "<class 'list'>\n",
      "[-1.]\n"
     ]
    }
   ],
   "source": [
    "def read_saved_files(attribute):\n",
    "    file_name = ''.join(attribute)+'_binary_classification.txt'\n",
    "    categories, file_names_dict = read_data_file(os.path.join(celebA_dir, file_name), image_dir)\n",
    "    categories = np.asarray(categories).ravel()\n",
    "    print(categories)\n",
    "    \n",
    "    print(\"Number of images: \", len(file_names_dict.keys()))\n",
    "    print(\"Few image names:\")\n",
    "    list(file_names_dict.keys())[0:5]\n",
    "    \n",
    "    label = file_names_dict[list(file_names_dict.keys())[0]]\n",
    "    print(type(label))\n",
    "    label = np.asarray(label)\n",
    "    print(label.ravel())\n",
    "    \n",
    "for attribute in attributes:\n",
    "     read_saved_files(attribute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "disco-container-notebook",
   "language": "python",
   "name": "disco-container-notebook"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
